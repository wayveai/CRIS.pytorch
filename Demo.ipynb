{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe7add10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wayve/saurabh/CRIS.pytorch/env/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from PIL import Image\n",
    "from model import build_segmenter\n",
    "from utils.dataset import RefDataset\n",
    "import utils.config as config\n",
    "from utils.dataset import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b4abf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-14 21:08:43.179 | INFO     | model:build_segmenter:41 - Backbone with decay=478, Head=124\n"
     ]
    }
   ],
   "source": [
    "model_dir = \"/dev/shm/saurabh/refcocog_g/CRIS_R101/\"\n",
    "args = config.load_cfg_from_cfg_file(\"config/refcocog_g/cris_r101.yaml\")\n",
    "model, _ = build_segmenter(args)\n",
    "model = torch.nn.DataParallel(model).cuda()\n",
    "model = model.eval()\n",
    "\n",
    "args.model_dir = os.path.join(model_dir, \"best_model.pth\")\n",
    "if os.path.isfile(args.model_dir):\n",
    "    checkpoint = torch.load(args.model_dir)\n",
    "    model.load_state_dict(checkpoint['state_dict'], strict=True)\n",
    "else:\n",
    "    raise ValueError(\n",
    "        \"=> resume failed! no checkpoint found at '{}'. Please check args.resume again!\"\n",
    "        .format(args.model_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7599f239",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_input_dir = \"orange_tennis.jpeg\"\n",
    "image_input = cv2.imread(image_input_dir)\n",
    "image_input = cv2.cvtColor(image_input, cv2.COLOR_BGR2RGB)\n",
    "rfd = RefDataset(None, None, None, None, None, input_size=args[\"input_size\"], word_length=args[\"word_len\"])\n",
    "image_tensor = rfd.convert_image_to_tensor(image_input)\n",
    "image_tensor = torch.unsqueeze(image_tensor, dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec9b5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef0fac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Image.fromarray(image_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125d8e34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#query = \"Both men in front of the cake\"\n",
    "query = \"Random\"\n",
    "sentence_tokens = tokenize(query, 22, True)\n",
    "sentence_tokens = sentence_tokens.cuda(non_blocking=True)\n",
    "pred = model(image_tensor, sentence_tokens)\n",
    "pred = torch.sigmoid(pred)\n",
    "\n",
    "if pred.shape[-2:] != image_tensor.shape[-2:]:\n",
    "    pred = F.interpolate(pred,\n",
    "                         size=image_tensor.shape[-2:],\n",
    "                         mode='bicubic',\n",
    "                         align_corners=True).squeeze()\n",
    "\n",
    "\n",
    "pred = pred.cpu().numpy()\n",
    "pred = np.array(pred > 0.35)\n",
    "pred = np.array(pred*255, dtype=np.uint8)\n",
    "h, w, _ = image_input.shape\n",
    "mat, mat_inv = rfd.getTransformMat(image_input.shape[:2], True)\n",
    "pred = cv2.warpAffine(pred, mat_inv, (w, h),\n",
    "                      flags=cv2.INTER_CUBIC,\n",
    "                      borderValue=0.)\n",
    "\n",
    "\n",
    "color = np.array([255, 0, 0])\n",
    "pred = np.expand_dims(pred, axis=2)\n",
    "mask = np.full_like(image_input, color)\n",
    "pred = np.concatenate((pred, pred, pred), axis=2)\n",
    "mask *= pred\n",
    "\n",
    "\n",
    "Image.fromarray(np.uint8(0.7*image_input + 0.3*pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bcb9c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
